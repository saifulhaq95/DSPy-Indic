{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae81be8a-5114-4663-86a7-3b36fef4301c",
   "metadata": {},
   "source": [
    "# Bootstrap few-shot CoT demonstations for IndicXLNI.\n",
    "\n",
    "IndicXNLI, is an NLI dataset for 11 Indian languages. It has been created by high-quality machine translation of the original English XNLI dataset.\n",
    "\n",
    "This notebook starts with a very simple Chain-of-Thought-based module for IndicXNLI.\n",
    "\n",
    "We found that bootstrapping demonstrations with DSPy improved performance by 15.9%. This is a single compilation step using dspy.BootstrapFewShotWithRandomSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1fb68-0713-41d1-95be-50cadb4a6408",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e43260-7813-4822-8d52-ebbb3614abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778cfcf7-50d6-494b-a2b6-5bfe8de4e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join('.', 'cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16e43a3-6a9a-4356-a039-ef2f22d765a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll rely on turbo for everything:\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-1106', max_tokens=250, model_type='chat')\n",
    "\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20670d29-6145-4847-87e7-4816a7c1a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggling this to true will redo the bootstrapping process. When\n",
    "# it is set to False, the existing demonstrations will be used but\n",
    "# turbo will still be used to evaluate the zero-shot and full programs.\n",
    "RUN_FROM_SCRATCH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40964a65-68be-433f-83c0-7a9f37064486",
   "metadata": {},
   "source": [
    "## IndicXLNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e30e0c6-1ff6-494b-bc8b-a3193a8f1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('Divyanshu/indicxnli', 'hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b4cb0-c393-47aa-8597-90b645ad637d",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d13cadd-32bc-4f74-ad2c-b997616385f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indicxlni(dataset, split=\"validation\"):\n",
    "    \n",
    "    data_df = pd.DataFrame(dataset[split])\n",
    "    label_map = {0: \"Yes\", 1: \"Neutral\", 2: \"No\"}\n",
    "    def as_example(row): \n",
    "        return dspy.Example({\n",
    "            \"premise\": row['premise'],\n",
    "            \"hypothesis\": row['hypothesis'],\n",
    "            \"answer\": label_map[row['label']]\n",
    "        }).with_inputs(\"premise\", \"hypothesis\")\n",
    "\n",
    "    return list(data_df.apply(as_example, axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e6820-67ed-478f-95b8-09018553a193",
   "metadata": {},
   "source": [
    "## Train and dev samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a00189-7fe1-4efc-9f07-b3dfda35a5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train = load_indicxlni(dataset, \"train\")\n",
    "all_dev = load_indicxlni(dataset, \"validation\")\n",
    "\n",
    "random.seed(1)\n",
    "random.shuffle(all_train)\n",
    "random.shuffle(all_dev)\n",
    "\n",
    "# 200 random train, 50 random dev:\n",
    "train, dev = all_train[: 200], all_dev[200: 250]\n",
    "\n",
    "len(train), len(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7672840-8af4-4273-aa21-e7c6f59b745b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c9dcb5-2c6b-47e4-bf8a-c805cc8d88f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "\n",
    "test = load_indicxlni(dataset, \"test\")\n",
    "\n",
    "# 100 random test:\n",
    "test = test[: 100]\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f4dc8-7046-4713-bb41-6df1669669d7",
   "metadata": {},
   "source": [
    "## Evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf44ce7-0a41-4e79-96ee-18634cdd3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicxlni_accuracy = dspy.evaluate.metrics.answer_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00ebac4-74bd-45f3-979a-43a2f8e12aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluate(devset=test, num_threads=1, display_progress=True, display_table=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc2235-ba32-4662-a9e0-f2df2c36d507",
   "metadata": {},
   "source": [
    "## Zero-shot CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5571419-cb3d-4d63-9f17-f21e7b8de0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicXLNISignature(dspy.Signature):\n",
    "    (\"\"\"You are given a premise and a hypothesis. \"\"\"\n",
    "    \"\"\"You must indicate with Yes/No/Neutral answer whether we can logically \"\"\"\n",
    "    \"\"\"conclude the hypothesis from the premise.\"\"\")\n",
    "\n",
    "    premise = dspy.InputField()\n",
    "    hypothesis = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Yes or No or Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4797ca-f711-454b-a9d0-86f4d93ead5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicXLNICoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(IndicXLNISignature)\n",
    "\n",
    "    def forward(self, premise, hypothesis):\n",
    "        return self.generate_answer(premise=premise, hypothesis=hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a06786-4c83-4e96-add7-55860598c4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cot_zeroshot = IndicXLNICoT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8faec8-462b-4cec-8bc2-5d4e7639775d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 100  (44.0): 100%|███████| 100/100 [02:00<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 100  (44.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(cot_zeroshot, metric=indicxlni_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c5859-5933-47a1-a283-a1a992c7c889",
   "metadata": {},
   "source": [
    "## Optimized few-shot with bootstrapped demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12714de6-9002-468d-95ac-67107330ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 8 traces per predictor.\n",
      "Will attempt to train 10 candidate sets.\n"
     ]
    }
   ],
   "source": [
    "bootstrap_optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    max_bootstrapped_demos=8,\n",
    "    max_labeled_demos=8,\n",
    "    num_candidate_programs=10,\n",
    "    num_threads=8,\n",
    "    metric=indicxlni_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb52d4ca-d25d-4f0c-a69b-0079ba322e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:29<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0%)\n",
      "Score: 32.0 for set: [0]\n",
      "New best score: 32.0 for seed -3\n",
      "Scores so far: [32.0]\n",
      "Best score: 32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 50  (36.0): 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18 / 50  (36.0%)\n",
      "Score: 36.0 for set: [8]\n",
      "New best score: 36.0 for seed -2\n",
      "Scores so far: [32.0, 36.0]\n",
      "Best score: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                       | 12/200 [00:35<09:21,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 50  (34.0): 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 50  (34.0%)\n",
      "Score: 34.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0]\n",
      "Best score: 36.0\n",
      "Average of max per entry across top 1 scores: 0.36\n",
      "Average of max per entry across top 2 scores: 0.46\n",
      "Average of max per entry across top 3 scores: 0.52\n",
      "Average of max per entry across top 5 scores: 0.52\n",
      "Average of max per entry across top 8 scores: 0.52\n",
      "Average of max per entry across top 9999 scores: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                       | 12/200 [00:37<09:51,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 7 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:29<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0%)\n",
      "Score: 38.0 for set: [8]\n",
      "New best score: 38.0 for seed 0\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0]\n",
      "Best score: 38.0\n",
      "Average of max per entry across top 1 scores: 0.38\n",
      "Average of max per entry across top 2 scores: 0.52\n",
      "Average of max per entry across top 3 scores: 0.58\n",
      "Average of max per entry across top 5 scores: 0.62\n",
      "Average of max per entry across top 8 scores: 0.62\n",
      "Average of max per entry across top 9999 scores: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                          | 4/200 [00:10<08:28,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0): 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0%)\n",
      "Score: 42.0 for set: [8]\n",
      "New best score: 42.0 for seed 1\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0]\n",
      "Best score: 42.0\n",
      "Average of max per entry across top 1 scores: 0.42\n",
      "Average of max per entry across top 2 scores: 0.52\n",
      "Average of max per entry across top 3 scores: 0.58\n",
      "Average of max per entry across top 5 scores: 0.66\n",
      "Average of max per entry across top 8 scores: 0.66\n",
      "Average of max per entry across top 9999 scores: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 2/200 [00:08<14:09,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 50  (46.0): 100%|██████████| 50/50 [00:28<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 50  (46.0%)\n",
      "Score: 46.0 for set: [8]\n",
      "New best score: 46.0 for seed 2\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.6\n",
      "Average of max per entry across top 5 scores: 0.7\n",
      "Average of max per entry across top 8 scores: 0.72\n",
      "Average of max per entry across top 9999 scores: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                         | 6/200 [00:17<09:33,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0): 100%|██████████| 50/50 [00:29<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0%)\n",
      "Score: 40.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.66\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.78\n",
      "Average of max per entry across top 9999 scores: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▉                                         | 9/200 [00:24<08:30,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:29<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0%)\n",
      "Score: 32.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.66\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.8\n",
      "Average of max per entry across top 9999 scores: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                      | 15/200 [00:35<07:15,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 16 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0): 100%|██████████| 50/50 [00:29<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0%)\n",
      "Score: 42.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0, 42.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.62\n",
      "Average of max per entry across top 5 scores: 0.72\n",
      "Average of max per entry across top 8 scores: 0.8\n",
      "Average of max per entry across top 9999 scores: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 2/200 [00:04<07:07,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 28  (28.6):  54%|█████▉     | 27/50 [00:16<00:13,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x7fb29b690dc0> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0): 100%|██████████| 50/50 [00:29<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0%)\n",
      "Score: 42.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0, 42.0, 42.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.62\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.82\n",
      "Average of max per entry across top 9999 scores: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                      | 16/200 [00:42<08:07,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:29<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0%)\n",
      "Score: 32.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0, 42.0, 42.0, 32.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.62\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.82\n",
      "Average of max per entry across top 9999 scores: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▊                                      | 18/200 [00:45<07:40,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 19 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0): 100%|██████████| 50/50 [00:29<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 50  (32.0%)\n",
      "Score: 32.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0, 42.0, 42.0, 32.0, 32.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.62\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.82\n",
      "Average of max per entry across top 9999 scores: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▎                                       | 11/200 [00:28<08:10,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0): 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0%)\n",
      "Score: 40.0 for set: [8]\n",
      "Scores so far: [32.0, 36.0, 34.0, 38.0, 42.0, 46.0, 40.0, 32.0, 42.0, 42.0, 32.0, 32.0, 40.0]\n",
      "Best score: 46.0\n",
      "Average of max per entry across top 1 scores: 0.46\n",
      "Average of max per entry across top 2 scores: 0.56\n",
      "Average of max per entry across top 3 scores: 0.62\n",
      "Average of max per entry across top 5 scores: 0.74\n",
      "Average of max per entry across top 8 scores: 0.86\n",
      "Average of max per entry across top 9999 scores: 0.9\n",
      "13 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_FROM_SCRATCH:\n",
    "    cot_fewshot = bootstrap_optimizer.compile(cot_zeroshot, trainset=train, valset=dev)\n",
    "else:\n",
    "    cot_fewshot = IndicXLNICoT()\n",
    "    cot_fewshot.load(\"indicxlni-cot_fewshot-turbo-gpt3.5-demos.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1b918ad-fe37-4cf5-b549-f44b31e58990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 100  (51.0): 100%|███████| 100/100 [04:13<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51 / 100  (51.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(cot_fewshot, metric=indicxlni_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5abf432e-4a37-4dd6-9154-b2a561e2d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_fewshot.save(\"indicxlni-cot_fewshot-turbo-gpt3.5-demos.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49ad56-7968-4aa3-8277-af3a9c98ded0",
   "metadata": {},
   "source": [
    "## Example prompt with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af416bae-a6cf-4488-9386-c31d74710873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "You are given a premise and a hypothesis. You must indicate with Yes/No/Neutral answer whether we can logically conclude the hypothesis from the premise.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Premise: ${premise}\n",
      "\n",
      "Hypothesis: ${hypothesis}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: Yes or No or Neutral\n",
      "\n",
      "---\n",
      "\n",
      "Premise: ब्रिटेन द्वारा गुआडलूप पर कब्जा करने के बाद, विक्टर ह्यूजेस, कन्वेंशन के कमिश्नर ने द्वीप को वापस ले लिया, गुलामी को समाप्त करने की घोषणा की और पुराने गार्ड कोलोन को गिलॉटिंग करने के बारे में सेट किया।\n",
      "\n",
      "Hypothesis: गुडेलोप ने ब्रिटेन पर कब्जा कर लिया।\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We know that after Britain took control of Guadeloupe, Victor Hugues, the commissioner of the Convention, took the island back, declared an end to slavery, and set up the old guard colony for guillotining.\n",
      "\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Premise: कर अपने युद्धों के लिए भुगतान करने के लिए बढ़ गया, और अधिक से अधिक किसानों को अपने खेतों को छोड़ना पड़ा जब उनकी सेनाओं में दबाव डाला गया।\n",
      "Hypothesis: कर केवल उसके युद्धों के लिए भुगतान करने के लिए बढ़ा, जिससे किसान अपने खेतों को त्यागने के लिए मजबूर हो गए।\n",
      "Answer: Neutral\n",
      "\n",
      "---\n",
      "\n",
      "Premise: इसी समय-और यहीं पर फोस्टर के सावधानीपूर्वक किए गए भेदभाव बहुत उपयोगी हैं-येट्स स्पष्ट रूप से वैचारिक कविता से घृणा करते थे।\n",
      "Hypothesis: येट्स ने सभी प्रकार की कविताओं को अलविदा कह दिया।\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Premise: यदि उनकी यात्रा का समाचार पहले ही फैल चुका था, तो हमले की खबर भी फैल गई होगी, लेकिन उन्हें गांव में दहशत का कोई संकेत नहीं मिला।\n",
      "Hypothesis: वह समझ नहीं पा रहा था कि गांव में घबराहट क्यों नहीं है।\n",
      "Answer: Neutral\n",
      "\n",
      "---\n",
      "\n",
      "Premise: क्या आप फोन को एक सेकंड के लिए धन्यवाद दे सकते हैं\n",
      "Hypothesis: अगर तुम पकड़े रहोगे, मैं अभी वापस आ जाऊंगा।\n",
      "Answer: Neutral\n",
      "\n",
      "---\n",
      "\n",
      "Premise: आप अरावली पहाड़ियों से घिरे झंडों, गुंबदों और पेड़ों के आकर्षक परिदृश्य के लिए छत पर चढ़ सकते हैं।\n",
      "Hypothesis: यहां से आपको पेड़ों का अच्छा दृश्य नहीं मिल सकता।\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Premise: जाहिर है कि नशीली दवाओं की लत गुलामों को अपने दर्द और डर को भूलने के लिए एक सुविधाजनक तरीका था, ताकि उन्हें यह सुनिश्चित करने के लिए जो कुछ भी आवश्यक था, उसे खुश करने के लिए हमेशा उत्सुक रखा जा सके कि बहुमूल्य, घातक राशन कभी न रुके।\n",
      "Hypothesis: गुलामों के लिए उनकी कठिनाइयों से बचने के लिए ड्रग्स एक सरल तरीका था।\n",
      "Answer: Yes\n",
      "\n",
      "---\n",
      "\n",
      "Premise: उनमें से कुछ मुझे लगता है कि बस उत्तेजना की जरूरत है\n",
      "Hypothesis: उनमें से कुछ को उत्तेजित करने की आवश्यकता नहीं है।\n",
      "Answer: No\n",
      "\n",
      "---\n",
      "\n",
      "Premise: उन्होंने कहा, \"हम आपके रहने के लिए एक जगह का भुगतान कर रहे हैं।\"\n",
      "\n",
      "Hypothesis: वे किसी भी चीज के लिए भुगतान नहीं करेंगे।\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know that they said they are paying for a place for you to stay.\n",
      "\n",
      "Answer: No\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
